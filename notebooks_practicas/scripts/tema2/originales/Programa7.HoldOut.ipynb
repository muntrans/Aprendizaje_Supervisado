{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-YRJLlPDgGIx"
      },
      "outputs": [],
      "source": [
        "import numpy as np # Para procesamiento de arrays\n",
        "from sklearn import datasets\n",
        "from sklearn.dummy import DummyClassifier # Modelo de machine learning (tampoco aprende mucho)\n",
        "# Clasificador \"aleatorio\" no tiene en cuenta patrones obtenidos en base a los atributos.\n",
        "# Saca un resultado en base una característica - Ejemplo: obten valor más repetído.\n",
        "from sklearn.model_selection import train_test_split # Herramientoas para la seleccion de modelos\n",
        "from sklearn.preprocessing import StandardScaler #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cjClS_AdgGIy",
        "outputId": "474df61f-a113-4490-c619-0439397809b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            "(150, 4)\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ],
      "source": [
        "# Carga de datos\n",
        "iris = datasets.load_iris()\n",
        "print(iris.keys()) # esta organizado en formato diccionario, saber las \"cabeceras\"\n",
        "print(iris[\"data\"].shape) # saber el tamaño del array = 150 muestras y 4 atributos\n",
        "\n",
        "print(iris.target_names) # lo mismo que: iris[\"data\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "llkpndgRgGIz",
        "outputId": "2eca41f1-057c-4245-b489-048baee123f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabla de datos: 150 instancias y 4 atributos\n",
            "Valores de la clase: {np.int64(0), np.int64(1), np.int64(2)}\n",
            "[0 1 2] [50 50 50]\n"
          ]
        }
      ],
      "source": [
        "# Mostrar características de la tabla de datos.\n",
        "print(\"Tabla de datos: %d instancias y %d atributos\" % (iris.data.shape[0], iris.data.shape[1])) # display número de muestras (numero de filas y columnas)\n",
        "print(\"Valores de la clase:\", set(iris.target)) # display numero de valores posibles en la variable objetivo\n",
        "\n",
        "# Cuantificamos el número de instancias que contiene el dataset por clase -- distribución marginal: número de muestras (ocurrencias) en cada clase\n",
        "valores, ocurrencias = np.unique(iris.target, return_counts=True)\n",
        "print(valores, ocurrencias) # 50 = 50 = 50, esta balanceado, todas las muestras igual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KmYzl5AqgGIz",
        "outputId": "2b42a482-926e-4f76-a73f-62ecd4c32e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  clases: [0 1 2]  ocurrencias:  [10  9 11]\n"
          ]
        }
      ],
      "source": [
        "# Empezamos con -> Test: hold-out (externo) split 80-20%. # Partición externa\n",
        "X_training, X_test, y_training, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42) #train_test_split train_test_split(la matriz de datos, el target, el porcentaje de test (20-30%),  una medida de reprodubilidad: una semilla aleatoria que marca como toma los datos y parametros de incio, en caso que haya fold añadimos su número)\n",
        "  # nos va adevolver:\n",
        "    # X_training --> la matriz de muestras y atributos para el entrenamiento\n",
        "    # X_test --> la mtriz de datos para test - lo reservamos para la evaluación\n",
        "    # y_training --> el target para entrenamiento\n",
        "    # y_test --> el target para test\n",
        "valores_test, ocur_test = np.unique(y_test, return_counts=True)\n",
        "  # valores_test: Guarda los valores únicos que aparecen en y_test (por ejemplo, si es clasificación binaria, serían [0, 1], o las clases que tengas)\n",
        "  # ocur_test: Guarda cuántas veces aparece cada uno de esos valores (las ocurrencias/frecuencias)\n",
        "print('Test: ', 'clases:', valores_test, ' ocurrencias: ', ocur_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S6a2htqSgGI0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pNPy-rxNgGI0",
        "outputId": "61a60773-59dc-431b-8125-ccc7ca0afa0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenamiento:   clases: [0 1 2]   ocurrencias: [32 30 34]\n",
            "Validation:      clases: [0 1 2]   ocurrencias: [ 8 11  5]\n"
          ]
        }
      ],
      "source": [
        "# Validación: hold-out (interno) split 80-20%. # Partición interna (la particion de la particion)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.2, random_state=42) # Hacemos un nuevo holdout para obtener los datos finales de train y de validacion\n",
        "valores_train, ocur_train = np.unique(y_train, return_counts=True)\n",
        "print('Entrenamiento: ', ' clases:', valores_train, '  ocurrencias:', ocur_train)\n",
        "\n",
        "# Estandarizar las características de entrenamiento y de test\n",
        "standardizer = StandardScaler() # Crear el modelo\n",
        "X_training = standardizer.fit_transform(X_training) # ajustar con los datos de entrenamiento\n",
        "X_test = standardizer.transform(X_test) # transformar con los datos de test\n",
        "X_val = standardizer.transform(X_val)\n",
        "\n",
        "valores_val, ocur_val = np.unique(y_val, return_counts=True)\n",
        "print('Validation:    ', ' clases:', valores_val, '  ocurrencias:', ocur_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VG0cwcbxgGI0"
      },
      "outputs": [],
      "source": [
        "# Construcción del objeto que contiene el algoritmo de aprendizaje.\n",
        "clf = DummyClassifier(strategy='prior', random_state=42) # instancia del algoritmo a crear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sjzZzjjmgGI1"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del algoritmo de aprendizaje.\n",
        "clf = clf.fit(X_train, y_train) # ajustar el algoritmo con los parámetros: ahi tenemos los atributos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_val = clf.predict(X_val) # para gacer la inducción a los datos de validación (predicciones)\n",
        "print(preds_val)\n",
        "preds_prob = clf.predict_proba(X_val) # devuelve un score de pertenecia a cada una de las clases\n",
        "print(preds_prob)"
      ],
      "metadata": {
        "id": "seYYxf2JvfPH",
        "outputId": "f04456e4-9d47-4a72-d711-a5f9c72ad95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "[[0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]\n",
            " [0.33333333 0.3125     0.35416667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1MLx-ePyv_2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bCtYHz19gGI1",
        "outputId": "9291fe00-891f-4495-c4e0-e1490ea431b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud en validación:  0.20833333333333334\n",
            "Exactitud en test:  0.36666666666666664\n"
          ]
        }
      ],
      "source": [
        "# Evaluación del algoritmo de aprendizaje con el método \"score\" que devuelve directamente la métrica de 'accuracy'-- al metodo score siempre le damos las etiquetas\n",
        " # En este caso la evaluación consiste en darle unos datos (X) al modelo y que prediga la clase (Y)\n",
        "val_accuracy = clf.score(X_val, y_val)\n",
        "print(\"Exactitud en validación: \", val_accuracy)\n",
        "\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "print(\"Exactitud en test: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "e_KVGI4SgGI2",
        "outputId": "c233ead9-025a-40f0-bd9c-92655a59bc80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones de validación  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Etiquetas reales validación [1 1 0 0 0 2 1 2 2 2 1 1 1 1 1 0 2 0 1 0 1 1 0 0]\n",
            "\n",
            "Predicciones de test  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Etiquetas reales test [1 1 0 0 0 2 1 2 2 2 1 1 1 1 1 0 2 0 1 0 1 1 0 0]\n"
          ]
        }
      ],
      "source": [
        "# Obtenemos las predicciones sobre conjunto de validación y de test\n",
        "y_pred_val = clf.predict(X_val)\n",
        "print('Predicciones de validación ', y_pred_val)\n",
        "print('Etiquetas reales validación', y_val)\n",
        "\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print('\\nPredicciones de test ', y_pred_val)\n",
        "print('Etiquetas reales test', y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7m3mB8NpgGI2",
        "outputId": "6afaedb5-b9cf-457c-ceb4-882ad24bfbb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud en validación  91.6667 %\n",
            "Exactitud en test  96.6667 %\n"
          ]
        }
      ],
      "source": [
        "# Aplicamos un ejemplo con un clasificador más complejo que el \"dummyclassifier\"\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC(C=0.5) # Definimos algoritmo - instanciar objeto de clase SVC -- (C=0.5) son sus hiperparámetros\n",
        "svc.fit(X_train, y_train) # Entrenamos modelo - hacemos el fit a los datos de entrenamiento\n",
        "\n",
        "val_accuracy = svc.score(X_val, y_val) # Evaluamos modelo en validación\n",
        "print('Exactitud en validación ', np.round(val_accuracy*100, 4), '%') # dara el acuracy en validación\n",
        "\n",
        "test_accuracy = svc.score(X_test, y_test) # Evaluamos modelo en test\n",
        "print('Exactitud en test ', np.round(test_accuracy*100, 4), '%') # dara el acuracy en test (evaluación)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvcrn_6qgGI3"
      },
      "outputs": [],
      "source": [
        "# Guardar modelo\n",
        "import pickle\n",
        "with open('../models/model.pickle', 'wb') as fw:\n",
        "    pickle.dump(model, fw)\n",
        "\n",
        "# Cargar modelo\n",
        "with open('../models/model.pickle', 'rb') as fr:\n",
        "    pickle.load(fr)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}